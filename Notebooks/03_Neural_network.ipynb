{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "16fbb539-8f8b-4d05-8b30-cf97fdcb255d",
   "metadata": {},
   "source": [
    "# Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a52c7165-1557-4dfc-9d48-830fa1fb80ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from tensorflow.keras.utils import set_random_seed\n",
    "import os\n",
    "\n",
    "# assigning random seed for reproducebility was taken from: https://stackoverflow.com/questions/51249811/reproducible-results-in-tensorflow-with-tf-set-random-seed\n",
    "seed = 42\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "np.random.seed(seed)\n",
    "set_random_seed(seed)\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tensorflow.keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPooling2D\n",
    "from tensorflow.keras.regularizers import l2\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras import layers\n",
    "from keras.applications import ConvNeXtTiny"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "800dd985-2c61-4418-a27e-28252157ba0d",
   "metadata": {},
   "source": [
    "___________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "# Neural Network\n",
    "\n",
    "Here we build a basic neural network to classify out images. The below code repurposed many aspects of previous projects I worked on with colleagues. Most of the neural network and metrics takes inspiration from [A plant disease classification project](https://github.com/DerikVo/DSI_project_4_plant_disease) and a single day [Hack-a-thon](https://github.com/DerikVo/NN_hackathon) to classify if an object was a hotdog or not a hotdog."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b123ab25-0e50-4827-bce3-c5001dfa3e3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the training and testing paths\n",
    "training_folder_path = '../Images/Training'\n",
    "testing_folder_path = '../Images/Testing'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "60332b77-10c4-4f05-ba32-74e67ce636ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# manually list out the class names\n",
    "class_names = ['glioma', 'meningioma', 'notumor', 'pituitary']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6578b198-899d-4895-b516-d50fbde7f912",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4000 images belonging to 4 classes.\n",
      "Found 1712 images belonging to 4 classes.\n",
      "Found 1311 images belonging to 4 classes.\n"
     ]
    }
   ],
   "source": [
    "datagen = ImageDataGenerator(validation_split=0.30)\n",
    "# Get the training data\n",
    "train_ds = datagen.flow_from_directory(\n",
    "    training_folder_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    classes=class_names,\n",
    "    class_mode='categorical',\n",
    "    subset='training',  # Set as training data\n",
    "    seed=42\n",
    ")\n",
    "\n",
    "# Get the validation data\n",
    "val_ds = datagen.flow_from_directory(\n",
    "    training_folder_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    batch_size=32,\n",
    "    classes=class_names,\n",
    "    class_mode='categorical',\n",
    "    subset='validation',  # Set as validation data\n",
    "    seed=42,\n",
    "    shuffle=False\n",
    ")\n",
    "\n",
    "# Get the test data\n",
    "test_ds = datagen.flow_from_directory(\n",
    "    testing_folder_path,\n",
    "    target_size=(256, 256),\n",
    "    color_mode='grayscale',\n",
    "    class_mode='categorical',\n",
    "    seed=42,\n",
    "    shuffle=False\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1d60f14-7a80-4d41-9f0b-37321623c2f1",
   "metadata": {
    "tags": []
   },
   "source": [
    "## First model\n",
    "This model uses many aspects of a prior project for [plant disease classification](https://github.com/DerikVo/DSI_project_4_plant_disease/tree/main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bc37376b-106d-4825-b43a-9df7fad9f3e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping = EarlyStopping(patience=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c3a1ac-2d85-467e-aa16-52f1c0f3ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1)))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, (3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b8c7002-7990-4b3a-8f57-84d867286e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "187b5f26-deb2-41a6-a960-439acf618f9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 87s 574ms/step - loss: 6.8223 - accuracy: 0.7800 - val_loss: 1.1457 - val_accuracy: 0.7775\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 50s 402ms/step - loss: 0.2138 - accuracy: 0.9258 - val_loss: 1.0864 - val_accuracy: 0.7079\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 54s 432ms/step - loss: 0.1285 - accuracy: 0.9575 - val_loss: 1.2109 - val_accuracy: 0.7623\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 81s 649ms/step - loss: 0.0572 - accuracy: 0.9820 - val_loss: 1.7071 - val_accuracy: 0.7407\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 55s 441ms/step - loss: 0.0271 - accuracy: 0.9905 - val_loss: 1.7876 - val_accuracy: 0.7815\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 82s 654ms/step - loss: 0.0348 - accuracy: 0.9902 - val_loss: 1.7913 - val_accuracy: 0.7523\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 81s 649ms/step - loss: 0.0084 - accuracy: 0.9985 - val_loss: 1.7633 - val_accuracy: 0.7687\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "669341b5-a852-4356-b160-e514bd785ca9",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('../Models/CNN_base.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d392525a-5df8-49aa-8380-a4f9b1257731",
   "metadata": {},
   "source": [
    "### Interpretation:\n",
    "Here we see that our training accuracy is about 99% while our validation is 76% which suggest our model is very overfit. We will need to either reduce features or add some regularization. The validation score is higher than our baseline, but the score is lower than [Munir)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7794124/) and their team's study accuracy of 87% (N=154). However, this is simply a supportive tool to assist radiologist, and the radiologist response would continue to train the model.\n",
    "\n",
    "For out next iteration, lets try adding some regularization to see if it can reduce overfitting so our model can be more generalized."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2187876c-e18e-4405-a1c1-d1deadafed1e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Second model\n",
    "This model uses regularization to try to combat overfiting. The model uses techniques learned from the [General Assembly Data science immersive bootcamp](https://generalassemb.ly/education/data-science) which taught a lab on regularization with convolutional neural networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d448bb82-875b-476a-803f-d487108b2d2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = Sequential()\n",
    "model2.add(Conv2D(32, (3, 3), activation='relu', input_shape=(256, 256, 1), kernel_regularizer=l2(0.01)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "\n",
    "model2.add(Conv2D(64, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Conv2D(128, (3, 3), activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model2.add(MaxPooling2D((2, 2)))\n",
    "model2.add(Dropout(0.25))\n",
    "\n",
    "model2.add(Flatten())\n",
    "model2.add(Dense(128, activation='relu', kernel_regularizer=l2(0.01)))\n",
    "model2.add(Dropout(0.5))\n",
    "\n",
    "model2.add(Dense(4, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cca64500-4aaf-4c7e-8593-aa43678ab694",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6e7cb709-ca5e-4790-a79d-57eb224495ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "125/125 [==============================] - 60s 458ms/step - loss: 21.2878 - accuracy: 0.6155 - val_loss: 6.0345 - val_accuracy: 0.6232\n",
      "Epoch 2/10\n",
      "125/125 [==============================] - 56s 449ms/step - loss: 4.9348 - accuracy: 0.7905 - val_loss: 5.2085 - val_accuracy: 0.5917\n",
      "Epoch 3/10\n",
      "125/125 [==============================] - 86s 683ms/step - loss: 3.9861 - accuracy: 0.8510 - val_loss: 4.1504 - val_accuracy: 0.7009\n",
      "Epoch 4/10\n",
      "125/125 [==============================] - 55s 441ms/step - loss: 3.2915 - accuracy: 0.8687 - val_loss: 3.8028 - val_accuracy: 0.7062\n",
      "Epoch 5/10\n",
      "125/125 [==============================] - 58s 460ms/step - loss: 2.8297 - accuracy: 0.8915 - val_loss: 3.3022 - val_accuracy: 0.7447\n",
      "Epoch 6/10\n",
      "125/125 [==============================] - 85s 678ms/step - loss: 2.4836 - accuracy: 0.8950 - val_loss: 2.9780 - val_accuracy: 0.7436\n",
      "Epoch 7/10\n",
      "125/125 [==============================] - 56s 445ms/step - loss: 2.2336 - accuracy: 0.9015 - val_loss: 2.7743 - val_accuracy: 0.7471\n",
      "Epoch 8/10\n",
      "125/125 [==============================] - 56s 443ms/step - loss: 2.0099 - accuracy: 0.9078 - val_loss: 2.5257 - val_accuracy: 0.7529\n",
      "Epoch 9/10\n",
      "125/125 [==============================] - 86s 684ms/step - loss: 1.8300 - accuracy: 0.9137 - val_loss: 2.6962 - val_accuracy: 0.7237\n",
      "Epoch 10/10\n",
      "125/125 [==============================] - 59s 473ms/step - loss: 1.7438 - accuracy: 0.9062 - val_loss: 2.4427 - val_accuracy: 0.7348\n"
     ]
    }
   ],
   "source": [
    "history2 = model2.fit(train_ds, validation_data=val_ds, epochs=10, callbacks=[early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c9b1043-ec1a-4132-ab02-75d33a558388",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2.save('../Models/CNN_regularization.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186eb61c-9b5c-4d31-8ddf-7a6af68147e8",
   "metadata": {
    "tags": []
   },
   "source": [
    "### Interpretation:\n",
    "Here we see that our training accuracy is about 90% while our validation is 73% which suggest our model is still overfit, but not as much. The model does better than our baseline model's accuracy of 46% but is less than the accuracy in [Munir's team's](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7794124/) study which found the accuracy of two radiologist was 87%.\n",
    "\n",
    "Since our validation score was higher without regularization we will stick with the first model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "27c2a852-8f70-4fbe-9d78-0507ea65995e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('../modules/')\n",
    "import model as m\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "feb981f9-8eda-4600-88ae-c6728603a387",
   "metadata": {
    "tags": []
   },
   "source": [
    "__________________________________________________________________________________________________________________________________________________________________________________________________________________\n",
    "# Conclusion:\n",
    "\n",
    "It appears our neural networks have similar scores. These score better than our baseline of 46%, but does less than the accuracy (87%) of the radiologist found in the [Munir et al. (2021)](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC7794124/) study. It should noted their sample size was 154 patients while this data set had over 7000 images; however, we need to keep in mind multiple images could be of the same patient.\n",
    "\n",
    "A neural network implementing augmentation was attempted, but that was an issue with running out of memory. There was attempts at saving the images instead, but that was causing conflicts as well so augmentation was scrapped.\n",
    "\n",
    "We will now proceed to our [Modeling Evaluation Notebook](../Notebooks/04_Model_evaluation.ipynb) to evaluate our models even further."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow-env]",
   "language": "python",
   "name": "conda-env-tensorflow-env-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
